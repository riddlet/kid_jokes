{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing kids jokes with LSTM\n",
    "\n",
    "The great/frustrating thing about this is that it doesn't need to work all that well in order to be satisfactory.\n",
    "\n",
    "The inspiration for this is one of my favorite twitter accounts, found [here](https://twitter.com/KidsWriteJokes)\n",
    "\n",
    "The data prep and model code was cobbled together mostly from these two sources:\n",
    "\n",
    "http://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/  \n",
    "https://beneyal.github.io/data-science-rnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pytumblr\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import AppAuthHandler\n",
    "from tweepy import Stream\n",
    "import urllib2\n",
    "import time\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect tumblr data\n",
    "\n",
    "For all data collection api token information is masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = pytumblr.TumblrRestClient(\n",
    "  'XXX',\n",
    "  'XXX',\n",
    "  'XXX',\n",
    "  'XXX'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posts = client.posts('badkidsjokes')\n",
    "total_posts = range(posts['total_posts'])\n",
    "for i in total_posts[20::20]:\n",
    "    page = client.posts('badkidsjokes', offset=i)\n",
    "    posts['posts'].extend(page['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('tumblrdat.json', 'w') as f:\n",
    "    json.dump(posts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "access_token = \"XXX\"\n",
    "access_token_secret = \"XXX\"\n",
    "consumer_key = \"XXX\"\n",
    "consumer_secret = \"XXX\"\n",
    "\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alltweets = []\n",
    "new_tweets = api.user_timeline(screen_name='KidsWriteJokes', count=200)\n",
    "alltweets.extend(new_tweets)\n",
    "if len(new_tweets)>0:\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    while len(new_tweets) > 0:\n",
    "        new_tweets=api.user_timeline(screen_name='KidsWriteJokes', count=200, max_id=oldest)\n",
    "        alltweets.extend(new_tweets)\n",
    "        oldest = alltweets[-1].id-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_tweets = api.user_timeline(screen_name='reallybadlaughs', count=200)\n",
    "alltweets.extend(new_tweets)\n",
    "if len(new_tweets)>0:\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    while len(new_tweets) > 0:\n",
    "        new_tweets=api.user_timeline(screen_name='reallybadlaughs', count=200, max_id=oldest)\n",
    "        alltweets.extend(new_tweets)\n",
    "        oldest = alltweets[-1].id-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alltweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('twitterdat.json', 'w') as f:\n",
    "    json.dump([tweet._json for tweet in alltweets], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def request_until_succeed(url):\n",
    "    \"\"\"\n",
    "    handles potential errors when sending a request\n",
    "    \"\"\"\n",
    "    \n",
    "    req = urllib2.Request(url)\n",
    "    success = False\n",
    "    while success is False:\n",
    "        try: \n",
    "            response = urllib2.urlopen(req)\n",
    "            if response.getcode() == 200:\n",
    "                success = True\n",
    "        except Exception, e:\n",
    "            print e\n",
    "            time.sleep(5)\n",
    "\n",
    "    return response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_id = 'XXX'\n",
    "app_secret = 'XXX'\n",
    "baseurl = 'https://graph.facebook.com/v2.8/kidswritejokes/feed/?fields=message'\n",
    "access_token = '&access_token=' + app_id + '|' + app_secret\n",
    "url = baseurl+access_token\n",
    "dat = json.loads(request_until_succeed(url))\n",
    "items=dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "has_next_page = True\n",
    "while has_next_page:\n",
    "    if 'paging' not in dat.keys():\n",
    "        break\n",
    "    \n",
    "    dat = json.loads(request_until_succeed(dat['paging']['next']))\n",
    "    items['data'].extend(dat['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('facebookdat.json', 'w') as f:\n",
    "    json.dump(items, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open and combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('facebookdat.json') as f:\n",
    "    fb_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('twitterdat.json') as f:\n",
    "    twitter_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('tumblrdat.json') as f:\n",
    "    tumblr_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jokes = []\n",
    "for i in fb_data['data']:\n",
    "    jokes.append(i['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in tumblr_data['posts']:\n",
    "    jokes.append(i['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in twitter_data:\n",
    "    jokes.append(i['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jokes = [BeautifulSoup(j, 'lxml').get_text() for j in jokes]\n",
    "#[j.lower() for j in jokes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep the data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corpus Length:', 123297)\n"
     ]
    }
   ],
   "source": [
    "CORPUS_LENGTH = None\n",
    "\n",
    "def get_corpus(joke_dat, verbose=0):\n",
    "    emoji_pattern = re.compile(\n",
    "        u\"(\\ud83d[\\ude00-\\ude4f])|\"  # emoticons\n",
    "        u\"(\\ud83c[\\udf00-\\uffff])|\"  # symbols & pictographs (1 of 2)\n",
    "        u\"(\\ud83d[\\u0000-\\uddff])|\"  # symbols & pictographs (2 of 2)\n",
    "        u\"(\\ud83d[\\ude80-\\udeff])|\"  # transport & map symbols\n",
    "        u\"(\\ud83c[\\udde0-\\uddff])\"  # flags (iOS)\n",
    "        u'\\U0001F300-\\U0001F64F'\n",
    "        u'\\U0001F680-\\U0001F6FF'\n",
    "        u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "        flags=re.UNICODE)\n",
    "    joke_dat = [t for t in joke_dat if 'http' not in t]\n",
    "    joke_dat = [t for t in joke_dat if '@' not in t]\n",
    "    joke_dat = [emoji_pattern.sub(r'', t) for t in joke_dat]\n",
    "    corpus = u' '.join(joke_dat)\n",
    "    global CORPUS_LENGTH\n",
    "    CORPUS_LENGTH = len(corpus)\n",
    "    if verbose:\n",
    "        print('Corpus Length:', CORPUS_LENGTH)\n",
    "    return corpus\n",
    "\n",
    "corpus = get_corpus(jokes, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('No. of unique characters:', 93)\n"
     ]
    }
   ],
   "source": [
    "N_CHARS = None\n",
    "\n",
    "def create_index_char_map(corpus, verbose=0):\n",
    "    chars = sorted(list(set(corpus)))\n",
    "    global N_CHARS\n",
    "    N_CHARS = len(chars)\n",
    "    if verbose:\n",
    "        print('No. of unique characters:', N_CHARS)\n",
    "    char_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "    idx_to_char = {i: c for i, c in enumerate(chars)}\n",
    "    return chars, char_to_idx, idx_to_char\n",
    "\n",
    "chars, char_to_idx, idx_to_char = create_index_char_map(corpus, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('No. of sequences:', 41086)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 40\n",
    "SEQ_STEP = 3\n",
    "N_SEQS = None\n",
    "\n",
    "def create_sequences(corpus, verbose=0):\n",
    "    sequences, next_chars = [], []\n",
    "    for i in range(0, CORPUS_LENGTH - MAX_SEQ_LENGTH, SEQ_STEP):\n",
    "        sequences.append(corpus[i:i + MAX_SEQ_LENGTH])\n",
    "        next_chars.append(corpus[i + MAX_SEQ_LENGTH])\n",
    "    global N_SEQS\n",
    "    N_SEQS = len(sequences)\n",
    "    if verbose:\n",
    "        print('No. of sequences:', len(sequences))\n",
    "    return np.array(sequences), np.array(next_chars)\n",
    "\n",
    "sequences, next_chars = create_sequences(corpus, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(sequences, next_chars, char_to_idx):\n",
    "    X = np.zeros((N_SEQS, MAX_SEQ_LENGTH, N_CHARS), dtype=np.bool)\n",
    "    y = np.zeros((N_SEQS, N_CHARS), dtype=np.bool)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for t, char in enumerate(sequence):\n",
    "            X[i, t, char_to_idx[char]] = 1\n",
    "            y[i, char_to_idx[next_chars[i]]] = 1\n",
    "    return X, y\n",
    "\n",
    "X, y = one_hot_encode(sequences, next_chars, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_5 (LSTM)                    (None, 40, 128)       113664      lstm_input_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 40, 128)       0           lstm_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                    (None, 128)           131584      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 128)           0           lstm_6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 93)            11997       dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 257,245\n",
      "Trainable params: 257,245\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(hidden_layer_size=128, dropout=0.2, learning_rate=0.01, verbose=0):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_layer_size, return_sequences=True, input_shape=(MAX_SEQ_LENGTH, N_CHARS)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(hidden_layer_size, return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(N_CHARS, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=learning_rate))\n",
    "    if verbose:\n",
    "        print('Model Summary:')\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "model = build_model(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.9990Epoch 00000: loss improved from inf to 1.99892, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 126s - loss: 1.9989   \n",
      "Epoch 2/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.8872Epoch 00001: loss improved from 1.99892 to 1.88650, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 126s - loss: 1.8865   \n",
      "Epoch 3/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.8072Epoch 00002: loss improved from 1.88650 to 1.80745, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 125s - loss: 1.8074   \n",
      "Epoch 4/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.7363Epoch 00003: loss improved from 1.80745 to 1.73648, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 126s - loss: 1.7365   \n",
      "Epoch 5/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.6881Epoch 00004: loss improved from 1.73648 to 1.68839, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 127s - loss: 1.6884   \n",
      "Epoch 6/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.6431Epoch 00005: loss improved from 1.68839 to 1.64301, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 127s - loss: 1.6430   \n",
      "Epoch 7/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.6079Epoch 00006: loss improved from 1.64301 to 1.60819, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 127s - loss: 1.6082   \n",
      "Epoch 8/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.5738Epoch 00007: loss improved from 1.60819 to 1.57353, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 127s - loss: 1.5735   \n",
      "Epoch 9/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.5423Epoch 00008: loss improved from 1.57353 to 1.54255, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.5425   \n",
      "Epoch 10/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.5194Epoch 00009: loss improved from 1.54255 to 1.51908, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 127s - loss: 1.5191   \n",
      "Epoch 11/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.4951Epoch 00010: loss improved from 1.51908 to 1.49498, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.4950   \n",
      "Epoch 12/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.4754Epoch 00011: loss improved from 1.49498 to 1.47537, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.4754   \n",
      "Epoch 13/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.4531Epoch 00012: loss improved from 1.47537 to 1.45319, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.4532   \n",
      "Epoch 14/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.4446Epoch 00013: loss improved from 1.45319 to 1.44489, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.4449   \n",
      "Epoch 15/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.4188Epoch 00014: loss improved from 1.44489 to 1.41837, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.4184   \n",
      "Epoch 16/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.4018Epoch 00015: loss improved from 1.41837 to 1.40163, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.4016   \n",
      "Epoch 17/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.3902Epoch 00016: loss improved from 1.40163 to 1.39000, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.3900   \n",
      "Epoch 18/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.3811Epoch 00017: loss improved from 1.39000 to 1.38159, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.3816   \n",
      "Epoch 19/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.3717Epoch 00018: loss improved from 1.38159 to 1.37111, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.3711   \n",
      "Epoch 20/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.3537Epoch 00019: loss improved from 1.37111 to 1.35393, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.3539   \n",
      "Epoch 21/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.3506Epoch 00020: loss improved from 1.35393 to 1.35123, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.3512   \n",
      "Epoch 22/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.3423Epoch 00021: loss improved from 1.35123 to 1.34254, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.3425   \n",
      "Epoch 23/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.3278Epoch 00022: loss improved from 1.34254 to 1.32847, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.3285   \n",
      "Epoch 24/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.3211Epoch 00023: loss improved from 1.32847 to 1.32128, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 129s - loss: 1.3213   \n",
      "Epoch 25/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.3163Epoch 00024: loss improved from 1.32128 to 1.31621, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.3162   \n",
      "Epoch 26/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2997Epoch 00025: loss improved from 1.31621 to 1.30005, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.3001   \n",
      "Epoch 27/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2873Epoch 00026: loss improved from 1.30005 to 1.28796, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.2880   \n",
      "Epoch 28/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2830Epoch 00027: loss improved from 1.28796 to 1.28356, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.2836   \n",
      "Epoch 29/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2789Epoch 00028: loss improved from 1.28356 to 1.27829, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.2783   \n",
      "Epoch 30/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2674Epoch 00029: loss improved from 1.27829 to 1.26769, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.2677   \n",
      "Epoch 31/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2599Epoch 00030: loss improved from 1.26769 to 1.26032, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.2603   \n",
      "Epoch 32/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2512Epoch 00031: loss improved from 1.26032 to 1.25056, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 127s - loss: 1.2506   \n",
      "Epoch 33/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2490Epoch 00032: loss improved from 1.25056 to 1.25013, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 129s - loss: 1.2501   \n",
      "Epoch 34/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2291Epoch 00033: loss improved from 1.25013 to 1.22930, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.2293   \n",
      "Epoch 35/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2397Epoch 00034: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.2398   \n",
      "Epoch 36/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2303Epoch 00035: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.2312   \n",
      "Epoch 37/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2262Epoch 00036: loss improved from 1.22930 to 1.22691, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 130s - loss: 1.2269   \n",
      "Epoch 38/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2182Epoch 00037: loss improved from 1.22691 to 1.21899, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.2190   \n",
      "Epoch 39/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2296Epoch 00038: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.2293   \n",
      "Epoch 40/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2207Epoch 00039: loss did not improve\n",
      "41086/41086 [==============================] - 129s - loss: 1.2205   \n",
      "Epoch 41/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2163Epoch 00040: loss improved from 1.21899 to 1.21653, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 129s - loss: 1.2165   \n",
      "Epoch 42/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1988Epoch 00041: loss improved from 1.21653 to 1.19912, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.1991   \n",
      "Epoch 43/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.2017Epoch 00042: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.2019   \n",
      "Epoch 44/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1874Epoch 00043: loss improved from 1.19912 to 1.18755, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 129s - loss: 1.1876   \n",
      "Epoch 45/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1986Epoch 00044: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.1980   \n",
      "Epoch 46/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1938Epoch 00045: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.1944   \n",
      "Epoch 47/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1806Epoch 00046: loss improved from 1.18755 to 1.17997, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 129s - loss: 1.1800   \n",
      "Epoch 48/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1775Epoch 00047: loss improved from 1.17997 to 1.17705, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.1770   \n",
      "Epoch 49/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1709Epoch 00048: loss improved from 1.17705 to 1.17109, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 129s - loss: 1.1711   \n",
      "Epoch 50/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1729Epoch 00049: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.1731   \n",
      "Epoch 51/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1525Epoch 00050: loss improved from 1.17109 to 1.15347, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.1535   \n",
      "Epoch 52/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1589Epoch 00051: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.1593   \n",
      "Epoch 53/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1594Epoch 00052: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.1591   \n",
      "Epoch 54/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1502Epoch 00053: loss improved from 1.15347 to 1.14997, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.1500   \n",
      "Epoch 55/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1423Epoch 00054: loss improved from 1.14997 to 1.14247, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.1425   \n",
      "Epoch 56/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1475Epoch 00055: loss did not improve\n",
      "41086/41086 [==============================] - 128s - loss: 1.1474   \n",
      "Epoch 57/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1406Epoch 00056: loss improved from 1.14247 to 1.14115, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.1412   \n",
      "Epoch 58/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1342Epoch 00057: loss improved from 1.14115 to 1.13370, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 129s - loss: 1.1337   \n",
      "Epoch 59/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1325Epoch 00058: loss improved from 1.13370 to 1.13270, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.1327   \n",
      "Epoch 60/60\n",
      "40960/41086 [============================>.] - ETA: 0s - loss: 1.1274Epoch 00059: loss improved from 1.13270 to 1.12729, saving model to weights_seq40_step3.hdf5\n",
      "41086/41086 [==============================] - 128s - loss: 1.1273   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model(model, X, y, batch_size=128, nb_epoch=60, verbose=0):\n",
    "    checkpointer = ModelCheckpoint(filepath=\"weights_seq40_step3.hdf5\", monitor='loss', verbose=verbose, save_best_only=True, mode='min')\n",
    "    model.fit(X, y, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose, callbacks=[checkpointer])\n",
    "\n",
    "train_model(model, X, y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception RuntimeError: RuntimeError('Failed to retrieve old handler',) in 'h5py._errors.set_error_handler' ignored\n",
      "Exception RuntimeError: RuntimeError('Failed to retrieve old handler',) in 'h5py._errors.set_error_handler' ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet no. 001\n",
      "=============\n",
      "Generating with seed:\n",
      "what did the women do in bed when she he\n",
      "________________________________________\n",
      "what did the women do in bed when she hear and a banana with no eyes\n",
      "\n",
      "because it was a boy and talk and said to get the sents a boy and a bo\n",
      "()\n",
      "Tweet no. 002\n",
      "=============\n",
      "Generating with seed:\n",
      "why did the zebra wear stripy pijamas\n",
      "be\n",
      "________________________________________\n",
      "why did the zebra wear stripy pijamas\n",
      "because they don’t have a fish with no eye\n",
      "\n",
      "\n",
      "a cheese was a boy and has a boy and the cow and said to \n",
      "()\n",
      "Tweet no. 003\n",
      "=============\n",
      "Generating with seed:\n",
      "Why did they let the turkey join the ban\n",
      "________________________________________\n",
      "Why did they let the turkey join the banana fart and a boy with a man and a boy and talk a baby poo in a banana and a boy and a boy and a pi\n",
      "()\n",
      "Tweet no. 004\n",
      "=============\n",
      "Generating with seed:\n",
      "what do cavemen eat\n",
      "\n",
      "caves\n",
      "__________________________\n",
      "what do cavemen eat\n",
      "\n",
      "cavesIYYYIIYYYYYYSYYYYYYYYYIYYYIYIIYSYYIYYYYYYIYYYYYYYIYYYYYIYYYYYYYYYYYYYYYYYYYYYYYYYIYYYYIYYYYYYYYYYYYY\n",
      "()\n",
      "Tweet no. 005\n",
      "=============\n",
      "Generating with seed:\n",
      "hi \n",
      "ok i ask you out \n",
      "but i haet you \n",
      "bu\n",
      "________________________________________\n",
      "hi \n",
      "ok i ask you out \n",
      "but i haet you \n",
      "but your butt\n",
      "but a cheese was a boy and talk of frum a hatman and a boy and has a hants to go to the \n",
      "()\n",
      "Tweet no. 006\n",
      "=============\n",
      "Generating with seed:\n",
      "Why cant the T-Rex clap its hands? Becau\n",
      "________________________________________\n",
      "Why cant the T-Rex clap its hands? Because they dont say to the school who do you call a cow with a man with a hants what do you call a cow \n",
      "()\n",
      "Tweet no. 007\n",
      "=============\n",
      "Generating with seed:\n",
      "What is pink, white and sits in corners \n",
      "________________________________________\n",
      "What is pink, white and sits in corners what do you call a man with a man a ha for a poo hard on the chicken land on the mother?\n",
      "\n",
      "A car.. wh\n",
      "()\n",
      "Tweet no. 008\n",
      "=============\n",
      "Generating with seed:\n",
      "A duck walks into a bar. A man runs out \n",
      "________________________________________\n",
      "A duck walks into a bar. A man runs out of my house and a boy and has a hant and a boy and talk and a boy and talk and a building with a har\n",
      "()\n",
      "Tweet no. 009\n",
      "=============\n",
      "Generating with seed:\n",
      "what do you call a deer with no eyes\n",
      "\n",
      "EY\n",
      "________________________________________\n",
      "what do you call a deer with no eyes\n",
      "\n",
      "EYE why did the suntina fall off the middle to have a poo butt butt for dubly with a cow with a hants \n",
      "()\n",
      "Tweet no. 010\n",
      "=============\n",
      "Generating with seed:\n",
      "what did a bee say to a other bee?\n",
      "i lov\n",
      "________________________________________\n",
      "what did a bee say to a other bee?\n",
      "i love you and what do you call a man with a camer of the cow with a col in a banana with no eyes\n",
      "\n",
      " ​what\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)\n",
    "def sample(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 0.2\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "def generate_tweets(model, corpus, char_to_idx, idx_to_char, n_tweets=10, verbose=0): \n",
    "    model.load_weights('weights_seq40_step3.hdf5')\n",
    "    tweets = []\n",
    "    #spaces_in_corpus = np.array([idx for idx in range(CORPUS_LENGTH) if corpus[idx] == ' '])\n",
    "    for i in range(1, n_tweets + 1):\n",
    "        sequence = np.random.choice(jokes)[0:MAX_SEQ_LENGTH]\n",
    "        #begin = np.random.choice(spaces_in_corpus)\n",
    "        tweet = u''\n",
    "        #sequence = corpus[begin:begin + MAX_SEQ_LENGTH]\n",
    "        tweet += sequence\n",
    "        if verbose:\n",
    "            print('Tweet no. %03d' % i)\n",
    "            print('=' * 13)\n",
    "            print('Generating with seed:')\n",
    "            print(sequence)\n",
    "            print('_' * len(sequence))\n",
    "        for _ in range(100):\n",
    "            x = np.zeros((1, MAX_SEQ_LENGTH, N_CHARS))\n",
    "            for t, char in enumerate(sequence):\n",
    "                x[0, t, char_to_idx[char]] = 1.0\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_idx = sample(preds)\n",
    "            next_char = idx_to_char[next_idx]\n",
    "\n",
    "            tweet += next_char\n",
    "            sequence = sequence[1:] + next_char\n",
    "        if verbose:\n",
    "            print(tweet)\n",
    "            print()\n",
    "        tweets.append(tweet)\n",
    "    return tweets\n",
    "\n",
    "tweets = generate_tweets(model, corpus, char_to_idx, idx_to_char, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.422718712303\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(sequences)\n",
    "Xval = vectorizer.transform(tweets)\n",
    "print(pairwise_distances(Xval, Y=tfidf, metric='cosine').min(axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary\n",
    "It does okay I suppose. It seems to get hung up on specific ideas (cows, bananas). I've toyed around with changing the sequence length (i.e. how many characters the model gets to predict the next value), and the sequence step. The sequence step is just a pragmatic alteration. Instead of modeling every possible sequence of letters, we're skipping some. This is just so I can fit this on my machine in a reasonable amount of time.\n",
    "\n",
    "Some other modifications I've got planned are to change the way the input data is structured. I'd like to train it joke-by-joke, rather than on the entire corpus as one long document. I'll also try to change the structure of the model a little bit (more/less regularization; change the hidden layer size). But probably the most likely way of improving this thing is just to get some more data. I'm increasingly thinking that if I train it on regular jokes that the output will more closely approximate the kids jokes. As it is, the kids jokes are nonsensical enough that the bot is just amping up the nonsense."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
